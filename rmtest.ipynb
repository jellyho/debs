{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66db456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/debs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/jellyho/Offline/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import glob, tqdm, wandb, os, json, random, time, jax\n",
    "from absl import app, flags\n",
    "from ml_collections import config_flags\n",
    "from log_utils import setup_wandb, get_exp_name, get_flag_dict, CsvLogger\n",
    "\n",
    "from envs.env_utils import make_env_and_datasets\n",
    "from envs.ogbench_utils import make_ogbench_env_and_datasets\n",
    "from envs.robomimic_utils import is_robomimic_env\n",
    "\n",
    "from utils.flax_utils import save_agent\n",
    "from utils.datasets import Dataset, ReplayBuffer\n",
    "\n",
    "from agents import agents\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00028c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/debs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/jellyho/Offline/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box, Dict\n",
    "import imageio\n",
    "import h5py\n",
    "\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic import DATASET_REGISTRY\n",
    "\n",
    "from utils.datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df9e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_dataset_exists(env_name):\n",
    "    # enforce that the dataset exists\n",
    "    task, dataset_type, hdf5_type = env_name.split(\"-\")\n",
    "    if hdf5_type == \"image\":\n",
    "        visual = True\n",
    "    else:\n",
    "        visual = False\n",
    "    if dataset_type == \"mg\":\n",
    "        file_name = \"low_dim_sparse_v15.hdf5\"\n",
    "    else:\n",
    "        if visual:\n",
    "            file_name = \"image_v15.hdf5\"\n",
    "        else:\n",
    "            file_name = \"low_dim_v15.hdf5\"\n",
    "    download_folder = os.path.join(\n",
    "        expanduser(\"~/.robomimic\"), \n",
    "        task,\n",
    "        dataset_type,\n",
    "        file_name\n",
    "    )\n",
    "    assert os.path.exists(download_folder)\n",
    "    \n",
    "    return download_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7137cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('file is not a database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "env_name = 'can-mh-image'\n",
    "dataset_path = _check_dataset_exists(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f5e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/jellyho/Offline/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment with name PickPlaceCan\n",
      "Action size is 7\n"
     ]
    }
   ],
   "source": [
    "env = EnvUtils.create_env_from_metadata(\n",
    "    env_meta=env_meta,\n",
    "    render=True, \n",
    "    render_offscreen=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c830f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_max_episode_length(env_name):\n",
    "    if env_name.startswith(\"lift\"):\n",
    "        return 300\n",
    "    elif env_name.startswith(\"can\"):\n",
    "        return 300\n",
    "    elif env_name.startswith(\"square\"):\n",
    "        return 400\n",
    "    elif env_name.startswith(\"transport\"):\n",
    "        return 800\n",
    "    elif env_name.startswith(\"tool_hang\"):\n",
    "        return 1000\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported environment: {env_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d05c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episode_length = _get_max_episode_length(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1b44b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wenv \u001b[38;5;241m=\u001b[39m \u001b[43mRobomimicImageWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episode_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_episode_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m, in \u001b[0;36mRobomimicImageWrapper.__init__\u001b[0;34m(self, env, init_state, normalization_path, render_obs_keys, render_hw, render_camera_name, max_episode_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m high \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(env\u001b[38;5;241m.\u001b[39maction_dimension, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m Box(\n\u001b[1;32m     31\u001b[0m     low\u001b[38;5;241m=\u001b[39mlow,\n\u001b[1;32m     32\u001b[0m     high\u001b[38;5;241m=\u001b[39mhigh,\n\u001b[1;32m     33\u001b[0m     shape\u001b[38;5;241m=\u001b[39mlow\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     34\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mlow\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m obs_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m observation_space \u001b[38;5;241m=\u001b[39m Dict()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obs_example\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[17], line 66\u001b[0m, in \u001b[0;36mRobomimicImageWrapper.get_observation\u001b[0;34m(self, raw_obs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_obs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m         raw_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_obs_keys:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_cache[k] \u001b[38;5;241m=\u001b[39m raw_obs[k]\n",
      "File \u001b[0;32m~/Offline/robomimic/robomimic/envs/env_robosuite.py:253\u001b[0m, in \u001b[0;36mEnvRobosuite.get_observation\u001b[0;34m(self, di)\u001b[0m\n\u001b[1;32m    251\u001b[0m ret \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m di:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mObsUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOBS_KEYS_TO_MODALITIES\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m ObsUtils\u001b[38;5;241m.\u001b[39mkey_is_obs_modality(key\u001b[38;5;241m=\u001b[39mk, obs_modality\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;66;03m# by default images from mujoco are flipped in height\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         ret[k] \u001b[38;5;241m=\u001b[39m di[k][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (k \u001b[38;5;129;01min\u001b[39;00m ObsUtils\u001b[38;5;241m.\u001b[39mOBS_KEYS_TO_MODALITIES) \u001b[38;5;129;01mand\u001b[39;00m ObsUtils\u001b[38;5;241m.\u001b[39mkey_is_obs_modality(key\u001b[38;5;241m=\u001b[39mk, obs_modality\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;66;03m# by default depth images from mujoco are flipped in height\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "wenv = RobomimicImageWrapper(env, max_episode_length=max_episode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac973ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobomimicImageWrapper(gym.Env):\n",
    "    def __init__(self, \n",
    "        env,\n",
    "        init_state=None,\n",
    "        normalization_path=None,\n",
    "        render_obs_keys=['agentview_image', 'robot0_eye_in_hand_image'],\n",
    "        render_hw=(256, 256),\n",
    "        render_camera_name=\"agentview\",\n",
    "        max_episode_length=None,\n",
    "        ):\n",
    "\n",
    "        self.env = env\n",
    "        self.render_obs_keys = render_obs_keys\n",
    "        self.init_state = init_state\n",
    "        self.render_hw = render_hw\n",
    "        self.render_camera_name = render_camera_name\n",
    "        self.video_writer = None\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.env_step = 0\n",
    "        self.n_episodes = 0\n",
    "\n",
    "        self.seed_state_map = dict()\n",
    "        self._seed = None\n",
    "        self.render_cache = {}\n",
    "        self.has_reset_before = False\n",
    "        \n",
    "        # setup spaces\n",
    "        low = np.full(env.action_dimension, fill_value=-1.)\n",
    "        high = np.full(env.action_dimension, fill_value=1.)\n",
    "        self.action_space = Box(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=low.shape,\n",
    "            dtype=low.dtype,\n",
    "        )\n",
    "\n",
    "        obs_example = self.get_observation()\n",
    "        observation_space = Dict()\n",
    "        for key, value in obs_example.items():\n",
    "            shape = value['shape']\n",
    "            min_value, max_value = -1, 1\n",
    "            if key.endswith('image'):\n",
    "                min_value, max_value = 0, 1\n",
    "            elif key.endswith('quat'):\n",
    "                min_value, max_value = -1, 1\n",
    "            elif key.endswith('qpos'):\n",
    "                min_value, max_value = -1, 1\n",
    "            elif key.endswith('pos'):\n",
    "                # better range?\n",
    "                min_value, max_value = -1, 1\n",
    "            else:\n",
    "                raise RuntimeError(f\"Unsupported type {key}\")\n",
    "            \n",
    "            this_space = Box(\n",
    "                low=min_value,\n",
    "                high=max_value,\n",
    "                shape=shape,\n",
    "                dtype=np.float32\n",
    "            )\n",
    "            observation_space[key] = this_space\n",
    "        self.observation_space = observation_space\n",
    "\n",
    "\n",
    "    def get_observation(self, raw_obs=None):\n",
    "        if raw_obs is None:\n",
    "            raw_obs = self.env.get_observation()\n",
    "        \n",
    "        for k in self.render_obs_keys:\n",
    "            self.render_cache[k] = raw_obs[k]\n",
    "\n",
    "        obs = dict()\n",
    "        for key in self.observation_space.keys():\n",
    "            obs[key] = raw_obs[key]\n",
    "        return obs\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed=seed)\n",
    "        self._seed = seed\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.init_state is not None:\n",
    "            if not self.has_reset_before:\n",
    "                # the env must be fully reset at least once to ensure correct rendering\n",
    "                self.env.reset()\n",
    "                self.has_reset_before = True\n",
    "\n",
    "            # always reset to the same state\n",
    "            # to be compatible with gym\n",
    "            raw_obs = self.env.reset_to({'states': self.init_state})\n",
    "        elif self._seed is not None:\n",
    "            # reset to a specific seed\n",
    "            seed = self._seed\n",
    "            if seed in self.seed_state_map:\n",
    "                # env.reset is expensive, use cache\n",
    "                raw_obs = self.env.reset_to({'states': self.seed_state_map[seed]})\n",
    "            else:\n",
    "                # robosuite's initializes all use numpy global random state\n",
    "                np.random.seed(seed=seed)\n",
    "                raw_obs = self.env.reset()\n",
    "                state = self.env.get_state()['states']\n",
    "                self.seed_state_map[seed] = state\n",
    "            self._seed = None\n",
    "        else:\n",
    "            # random reset\n",
    "            raw_obs = self.env.reset()\n",
    "\n",
    "        # return obs\n",
    "        obs = self.get_observation(raw_obs)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        raw_obs, reward, done, info = self.env.step(action)\n",
    "        obs = self.get_observation(raw_obs)\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def render(self, mode='rgb_array'):\n",
    "        if self.render_cache is None:\n",
    "            raise RuntimeError('Must run reset or step before render.')\n",
    "        img = np.moveaxis(self.render_cache, 0, -1)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "env, eval_env, train_dataset, val_dataset = make_env_and_datasets('can-mh-image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
